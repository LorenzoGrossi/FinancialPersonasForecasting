{\rtf1\ansi\ansicpg1252\cocoartf2513
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fswiss\fcharset0 Helvetica-Bold;\f2\froman\fcharset0 Times-Roman;
\f3\fnil\fcharset77 ZapfDingbatsITC;\f4\fnil\fcharset0 HelveticaNeue-Bold;\f5\fnil\fcharset0 HelveticaNeue;
}
{\colortbl;\red255\green255\blue255;\red49\green49\blue49;\red255\green255\blue255;\red0\green0\blue0;
\red12\green12\blue12;}
{\*\expandedcolortbl;;\cssrgb\c25098\c25098\c25098;\cssrgb\c100000\c100000\c100000;\cssrgb\c0\c0\c0;
\cssrgb\c5098\c5098\c5098;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}.}{\leveltext\leveltemplateid1\'01.;}{\levelnumbers;}\fi-360\li720\lin720 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid2\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li1440\lin1440 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid101\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid2}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\qc\partightenfactor0

\f1\b\fs40 \cf0 LINK DA BIBLIOGRAFIA
\f0\b0 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\fs24 \cf0 \
https://machinelearningmastery.com/nested-cross-validation-for-machine-learning-with-python/\
\
https://it.mathworks.com/help/stats/classificationlearner-app.html\
\
https://it.mathworks.com/help/stats/train-classification-models-in-classification-learner-app.html#bu3xete\
\
https://machinelearningmastery.com/k-fold-cross-validation/\
\
https://machinelearningmastery.com/classification-and-regression-trees-for-machine-learning/\
\
https://www.youtube.com/watch?v=9w16p4QmkAI\
\
https://www.youtube.com/watch?v=ZVR2Way4nwQ\
\
https://www.kdnuggets.com/2020/01/decision-tree-algorithm-explained.html\
\
https://machinelearningmastery.com/classification-and-regression-trees-for-machine-learning/\
\
https://en.wikipedia.org/wiki/Decision_tree_pruning\
\
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 \expnd0\expndtw0\kerning0
Ahmed BenSa\'efda (2024).\'a0Shapiro-Wilk and Shapiro-Francia normality tests.\'a0(https://www.mathworks.com/matlabcentral/fileexchange/13964-shapiro-wilk-and-shapiro-francia-normality-tests), MATLAB Central File Exchange. Recuperato\'a0aprile 11, 2024.\
\
https://royalsociety.org/-/media/policy/projects/privacy-enhancing-technologies/Synthetic_Data_Survey-24.pdf\
\
https://mostly.ai/blog/how-to-generate-synthetic-data\
\
https://neptune.ai/blog/cross-validation-in-machine-learning-how-to-do-it-right\
\
https://machinelearningmastery.com/k-fold-cross-validation/\
\
https://machinelearningmastery.com/training-validation-test-split-and-cross-validation-done-right/\
\
https://scikit-learn.org/stable/modules/cross_validation.html\
\
\pard\pardeftab720\partightenfactor0

\f2 \cf4 \cb1 Optimality of training/test size and resampling effectiveness in cross-validation
\f3 \uc0\u10025 
\f2  Georgios Afendras, Marianthi Markatou * Department of Biostatistics and Jacobs School of Medicine and Biomedical Sciences, University at Buffalo, United States (in DOWNLOAD, MAIN.PDF)
\f0 \cf0 \kerning1\expnd0\expndtw0 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 \

\f1\b ChatGPT:\

\f0\b0 \'93
\f4\b\fs32 \cf5 \cb3 	
\fs20 \expnd0\expndtw0\kerning0
Train/Cross-validation Sample (with k-fold cross-validation)
\f5\b0 :\cb1 \
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\partightenfactor0
\ls1\ilvl1\cf5 \cb3 \kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
In this setup, you divide your data into two parts: the training set and the cross-validation set.\cb1 \
\ls1\ilvl1\cb3 \kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
The training set is used to train your model.\cb1 \
\ls1\ilvl1\cb3 \kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
The cross-validation set is used to tune hyperparameters and evaluate the model's performance during training.\cb1 \
\ls1\ilvl1\cb3 \kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
With k-fold cross-validation, you further partition the training set into k subsets (folds). You iterate through each fold, using it as the validation set while training the model on the rest of the data. This process helps in better assessing the model's performance and reduces the risk of overfitting.\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa400\partightenfactor0
\ls1\ilvl0
\f4\b \cf5 \cb3 \kerning1\expnd0\expndtw0 {\listtext	.	}\expnd0\expndtw0\kerning0
Pure Cross-validation
\f5\b0 :\cb1 \
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\partightenfactor0
\ls1\ilvl1\cf5 \cb3 \kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
This usually refers to a scenario where you have a separate dedicated dataset solely for cross-validation purposes.\cb1 \
\ls1\ilvl1\cb3 \kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
In this setup, you have your training data for model training and a separate cross-validation dataset for model evaluation and hyperparameter tuning.\cb1 \
\ls1\ilvl1\cb3 \kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
Pure cross-validation doesn't involve further partitioning the training data as in k-fold cross-validation. Instead, it relies on a separate validation dataset.\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa400\partightenfactor0
\ls1\ilvl0
\f4\b \cf5 \cb3 \kerning1\expnd0\expndtw0 {\listtext	.	}\expnd0\expndtw0\kerning0
Test Sample
\f5\b0 :\cb1 \
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\partightenfactor0
\ls1\ilvl1\cf5 \cb3 \kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
This is a completely independent dataset, separate from both the training and cross-validation sets.\cb1 \
\ls1\ilvl1\cb3 \kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
The test set is used to assess the model's performance after training and validation are completed.\cb1 \
\ls1\ilvl1\cb3 \kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
It serves as a final evaluation to measure how well the model generalizes to unseen data.\cb1 \
\pard\pardeftab720\sa400\partightenfactor0
\cf5 \cb3 In summary:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls2\ilvl0
\f4\b \cf5 \kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
Train/Cross-validation Sample with k-fold cross-validation
\f5\b0  involves splitting the data into training and cross-validation sets, further divided into k subsets for cross-validation.\cb1 \
\ls2\ilvl0
\f4\b \cb3 \kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
Pure Cross-validation
\f5\b0  involves having a separate dataset solely for cross-validation purposes.\cb1 \
\ls2\ilvl0
\f4\b \cb3 \kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
Test Sample
\f5\b0  is a distinct dataset used for final model evaluation.\
\pard\tx566\pardeftab720\partightenfactor0

\fs32 \cf5 \cb1 \'93\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 \kerning1\expnd0\expndtw0 \
\
https://machinelearningmastery.com/machine-learning-in-r-step-by-step/\
}