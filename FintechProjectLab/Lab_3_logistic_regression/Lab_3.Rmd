---
title: "Laboratorio con `R` - 3"
author: 
date: 
output:
  html_document:
    df_print: paged
pdf_document: yes
subtitle: Metodi e Modelli per l'Inferenza Statistica - Ing. Matematica - a.a. 2019-20
number_sections: yes
toc: 
urlcolor: blue
---

## 0. Librerie
```{r load_libraries, results='hide', message = FALSE, warning=FALSE, eval = TRUE, collapse = TRUE }
library( rms )
library(arm)
library(ResourceSelection)
library(pROC)
```

## Reference:
Agresti, A. (2003). Categorical data analysis (Vol. 482). John Wiley & Sons.

## 1. Regressione logistica semplice

Prendiamo in esame il dataset relativo ad uno studio clinico su pazienti affetti da disturbi coronarici. In particolare, l'obiettivo dello studio consiste nello spiegare la presenza o l'assenza di significativi disturbi coronarici (CHD) in funzione dell'età (variabile AGE) dei pazienti. I dati si riferiscono a 100 pazienti. Le variabili del database sono descritte nel file *CHDAGE_data_description.txt*:

* __CHD__ variabile dipendente binaria: 1 se il disturbo è presente, 0  se il disturbo è assente;

* __AGE__ variabile indipendente ( continua ).

Sito da cui trarre dati e dataset http://www.umass.edu/statdata/statdata/

__Soluzione__

Importiamo i dati.

```{r load_chd, eval = TRUE, collapse = TRUE }
chd = read.table( "CHDAGE_data.txt", head = TRUE )

str( chd )

head( chd )

attach( chd )
```

Visualizziamo i dati.

```{r vis_chd, eval = TRUE, collapse = TRUE }

plot( AGE, CHD, pch = ifelse( CHD == 1, 3, 4 ),
      col = ifelse( CHD == 1, 'forestgreen', 'red' ),
      xlab = 'Age', ylab = 'CHD', main = 'CHD vs. Age', lwd = 2, cex = 1.5 )
```

Eseguiamo quindi un'analisi descrittiva del dataset.

Per meglio comprendere la natura della relazione è opportuno suddividere i pazienti in classi d'età e calcolare la media della variabile dipendente in ciascuna classe.

Inseriamo nel vettore $x$ i limiti delle classi d'età che si vogliono creare (questo passaggio è arbitrario, e va esguito con buon senso).

```{r div_class_age_chd, eval = TRUE, collapse = TRUE }
min( AGE )
max( AGE )

x  = c( 20, 29, 34, 39, 44, 49, 54, 59, 70 )

# Calcoliamo i punti medi degli intervalli che abbiamo creato
mid = c( ( x [ 2:9 ] + x [ 1:8 ] )/2 )

# Suddividiamo i dati nelle classi che abbiamo creato
GRAGE = cut( AGE, breaks = x, include.lowest = TRUE, right = FALSE )
GRAGE
```

Calcoliamo quindi la media della variabile AGE stratificata e sovrapponiamo i valori di y al grafico precedente.

```{r vis_graage_chd, eval = TRUE, collapse = TRUE }
y = tapply( CHD, GRAGE, mean )
y


plot( AGE, CHD, pch = ifelse( CHD == 1, 3, 4 ),
      col = ifelse( CHD == 1, 'forestgreen', 'red' ),
      xlab = 'Age', ylab = 'CHD', main = 'CHD vs. Age', lwd = 2, cex = 1.5 )
points( mid, y, col = "blue", pch = 16 )
```

Dal grafico si intuisce la natura della relazione fra AGE e CHD (all'aumentare dell'età, aumenta anche il rischio di avere problemi alle coronarie).

Identifichiamo un modello che descriva adeguatamente i nostri dati. Il modello più opportuno è un modello lineare generalizzato con link function di tipo `logit`, modelliamo cioè la relazione tra i nostri dati come:
$$
\mathbb{E}[y|x] = \mathbb{P} (y = 1|x) = \frac{e^{\beta_0 + \beta_1 x}}{1 + e^{\beta_0 + \beta_1 x}} \Leftrightarrow logit(\pi) = \log \big( \frac{\mathbb{P} (y = 1|x)}{1-\mathbb{P} (y = 1|x)} \big) = \beta_0 + \beta_1 x
$$
dove $\pi = \mathbb{P} (y = 1|x)$.

```{r glm_chd, eval = TRUE, collapse = TRUE }
help( glm )

mod = glm( CHD ~ AGE, family = binomial( link = logit ) )
summary( mod )
```

Il modello stimato è quindi:
$$
\text{logit}( \pi )  = -5.30945 + 0.11092 \cdot \text{AGE}
$$
in cui $\pi$ è la probabilità che CHD sia pari ad 1. 

Calcoliamo i valori stimati per il logit della probabilità di avere disturbi coronarici (sono i logit di $\pi_i$, che giustamnte hanno un range continuo).

```{r lin_pred_chd, eval = TRUE, collapse = TRUE }
mod$linear.predictors
```

Caliamo i valori stimati per la probabilità di avere disturbi coronarici ( che coincidono con gli esponenziali dei valori ottenuti al punto prima ). Sono le $\pi_i$ predette, pertanto comprese in [0, 1].

```{r fitt_val_chd, eval = TRUE, collapse = TRUE }
mod$fitted.values
```

Facciamo un grafico della predizione del modello.
```{r vis_pred_chd, eval = TRUE, collapse = TRUE }
plot( AGE, CHD, pch = ifelse( CHD == 1, 3, 4 ),
      col = ifelse( CHD == 1, 'forestgreen', 'red' ),
      xlab = 'Age', ylab = 'CHD', main = 'CHD vs. Age', lwd = 2, cex = 1.5 )
points( mid, y, col = "blue", pch = 16 )
lines( AGE, mod$fitted, col = 'darkblue' )
```

__Interpretazione dei coefficienti__ 

Uno dei motivi per cui la tecnica di regressione logistica è largamente diffusa, specialmente
in ambito clinico, è che i coefficienti del modello hanno una naturale interpretazione in termini di __odds ratio__ (__OR__).

Si consideri un predittore x dicotomico a livelli 0 e 1.
Si definisce odds che y = 1 fra gli individui con x = 0 la quantità:

$$
            \frac{\mathbb{P}( y = 1 | x = 0 )}{  1 - \mathbb{P}( y = 1 | x = 0 )}.
$$

Analogamente per i soggetti con x = 1, l'odds che y = 1 è:

$$
          \frac{\mathbb{P}( y = 1 | x = 1 )}{  1 - \mathbb{P}( y = 1 | x = 1 )}.
$$

L'OR è definito come il rapporto degli odds per x = 1 e x = 0.

Dato che:

$$
\mathbb{P}( y = 1 | x = 1 ) = \frac{\exp( \beta_0 + \beta_1 \cdot x)}{ 1 + \exp( \beta_0 + \beta_1\cdot x )}
$$

$$
      \mathbb{P}( y = 1|x = 0 ) = \frac{\exp( \beta_0 )}{ 1 + \exp( \beta_0 ) }
$$

Il che implica:

$$
 \text{OR} = \exp( \beta_1 )
$$

Si possono costruire intervalli di confidenza e generalizzazioni al caso di variabile x con più categorie in modo immediato.

Calcoliamo quindi l'OR relativo a AGE.

```{r summ_chd, eval = TRUE, collapse = TRUE }
summary( mod )

```

Il coefficiente della variabile AGE vale 0.111 e vediamo che secondo il test di ipotesi di Wald riportato nelle due colonne di destra del summary, il coefficiente è significativo. Il test di Wald nel caso univariato usa la statistica $Z = {\frac {({\widehat {\theta }}-\theta)^{2}}{\operatorname {var} ({\hat {\theta }})}}$, che va come una $\chi^2$. Ricordiamo che ${\hat {\theta }} = argmax_{\theta \in \Theta }~{\mathcal {L}}(\theta )$ (i coefficienti della regressione logistica si trovano attraverso stima di massima verosimiglianza).

Quindi l'OR per un incremento di 10 anni d'età è:

```{r OR_chd, eval = TRUE, collapse = TRUE }
exp( 10 * coef( mod ) [ 2 ] )
```

per ogni incremento di 10 anni d'età, il rischio di disturbo coronarico aumenta di 3 volte circa.

__N.B.__: il modello sottointende che il logit sia lineare nella variabile età, ossia che l'OR fra persone di 20 contro 30 anni sia lo stesso che fra individui di 40 contro 50 anni.

__IC per la regressione logistica__

Calcoliamo un intervallo di confidenza al $95\%$ per l'OR per un incremento di 10 anni d'età.

```{r IC_chd, eval = TRUE, collapse = TRUE }
alpha = 0.05
qalpha =  qnorm( 1 - alpha/2 )
qalpha

IC.sup = exp( 10 * coef( mod ) [ 2 ]  + qalpha * 10 * summary( mod )$coefficients[ 2, 2 ] )
IC.inf = exp( 10 * coef( mod ) [ 2 ] - qalpha * 10 * summary( mod )$coefficients[ 2, 2 ] )
c( IC.inf, IC.sup )
```

Per costruire in `R` l'intervallo di confidenza del logit si può partire dal calcolo della matrice di covarianza dei parametri $\beta$ stimati:

```{r vcov_chd, eval = TRUE, collapse = TRUE }
V = vcov( mod )
V
```

Per calcolare l'IC predittivo, abbiamo bisogno di calcolare l'errore standard, che in questo caso misura la curvatura della log-likelihood trovata per stimare la probabilità. Si trova come la radice quadrata del reciproco dell'informazione di Fisher (valutata alla massima verosimiglianza).
Per esempio, scegliendo un valore casuale (tipo AGE=50) possiamo trovarla come:

```{r plot_IC_chd, eval = TRUE, collapse = TRUE }
x = 50

# errore standard
predict( mod, data.frame( AGE = 50 ), se = TRUE )

# oppure
sqrt( V [ 1, 1 ]  + x^2 * V [ 2, 2 ]  + 2 * x * V [ 1, 2 ] )
```

Rappresentiamo graficamente l'intervallo di confidenza (al 95%) della regressione:

```{r plot_IC_chd2, eval = TRUE, collapse = TRUE }
# griglia di valori di x in cui valutare la regressione
grid = ( 20:69 )

se = predict( mod, data.frame( AGE = grid ), se = TRUE )
# errori standard corrispondenti ai valori della griglia

help( binomial )
gl = binomial( link = logit )  # funzione di link utilizzata
# Family objects provide a convenient way to specify the details of the models
# used by functions such as glm.


plot( mid, y, col = "red", pch = 3, ylim = c( 0, 1 ), ylab = "Probability of CHD",
      xlab = "AGE", main = "IC per la Regressione Logistica" )
lines( grid, gl$linkinv( se$fit ) )
lines( grid, gl$linkinv( se$fit - qnorm( 1-0.025 ) * se$se ), col = "red", lty = 2 )
lines( grid, gl$linkinv( se$fit + qnorm( 1-0.025 ) * se$se ), col = "red", lty = 2 )
```


__N.B.__ la funzione `gl$linkinv` permette di ottenere il valore delle probabilità a partire dalla link function (logit).


__Goodness of fit__

Varie tecniche sono state sviluppate e confrontate per stabilire la bontà del fit di una regressione logistica. Problema: tali tecniche soffrono di una limitata potenza (tipicamente non superiore al $50\%$) per campioni di dimensione contenuta (indicativamente $n < 400$).

Se la variabile indipendente è categorica si possono paragonare i valore di Devianza del modello fittato con il valore critico di una distribuzione $\chi^2( n-p )$,  dove p è il numero di parametri del modello.
Se la statistica $D$ è maggiore del valore critico si rifiuta l'ipotesi nulla che il modello sia un buon fit.

Se la variabile indipendente è continua ( es in questione ), la procedura precedente perde di validità e i valori P che si ottengono non sono corretti. L'alternativa che `R` fornisce richiede l' installazione di due librerie supplementari ( `Design` e `Hmisc`), che contengono le funzioni lrm e residuals per calcolare tale statistica.

```{r gof_chd, eval = TRUE, collapse = TRUE }
# library( rms )
# help( lrm )

mod2 = lrm( CHD ~ AGE, x = TRUE, y = TRUE )
mod2
```
Il __Model Likelihood Ratio Test__ riguarda la GOF di due modelli in competizione. E' basato sulla statistica $\lambda _{\text{LR}}=-2\left[~\ell (\theta _{0})-\ell ({\hat {\theta }})~\right]$, con ${\displaystyle \ell ({\hat {\theta }})\equiv \ln \left[~\sup _{\theta \in \Theta }{\mathcal {L}}(\theta )~\right]~}$. 

La statistica $\lambda_{LR}$ rappresenta la devianza. La devianza è un concetto chiave nella regressione logistica, perchè misura appunto la deviazione che il modello logistico che abbiamo fittato ha rispetto al modello che predice perfettamente le probabilità dei valori della variabile dipendente.

Se questa statistica è significativamente diversa da 1, allora possiamo considerare il modello completo, come in questo caso. Asintoticamente, è equivalente al test di Wald.

We can also visualize the residuals with a binned plot: average residuals vs independent variable (or vs predicted $\pi$ for multivariate regression). 
```{r binned, eval = TRUE, collapse = TRUE }
binnedplot(AGE, rstandard(mod))
```
In questo caso, osserviamo un fit abbastanza buono del modello (reisidui concentrati intorno allo 0), eccetto per le osservazioni con circa 55 anni, che sono leggermente sovrastimate.

Alternativamente, possiamo usare come GOF test, il test di __Hosmer-Lemeshow__. La statistica è stata costruita come segue:
$$ 
H = \sum_{g=1}^G \frac{(O_{1g} - E_{1g})^2}{N_g \pi_g (1-\pi_g)} \sim \chi^2_{G-2}
$$
dove $O_{1g}$ è il numero delle unità statistiche per cui si osserva un outcome pari ad 1; $E_{1g}$ è il numero delle unità statistiche per cui viene predetto 1 come outcome. Entrambe le quantità sono calcolate rispetto al gruppo g-esimo. Il numero totale di gruppi G presi in esame è deciso a priori a seconda delle variabili a disposizione. $\pi_g$ denota il rischio predetto per il g-esimo gruppo e $N_g$ è il numero totale di osservazioni nel gruppo G.


```{r res_hosl_chd, eval = TRUE, collapse = TRUE }
hoslem.test( mod$y, fitted( mod ), g = 10 )
```

In questo test dobbiamo scegliere g, numero di gruppi. Nel paper originale è suggerito di scegliere $g > p$, in questo caso quindi $g > 2$ (intercetta e AGE). Si vede che, anche cambiando g, giungiamo alla stessa conlusione, ovvero il modello fitta bene i dati. In generale la scelta del numero di gruppi a priori è un limite di questo test.


## 2. Regressione logistica multipla

In questo esercizio analizzeremo un dataset clinico inerente al peso di neonati.
Lo scopo dello studio consiste nell'identificare i fattori di rischio associati con il partorire bambini di peso inferiore ai 2500 grammi ( low birth weight ). I dati si riferiscono a n = 189 donne.

Le variabili del database sono descritte nel file "LOWBWT_data_description.txt":

* __LOW__: variabile dipendente binaria ( 1 se il neonato pesa meno di 2500 grammi, 0 viceversa );

* __AGE__, __LWT__, __FTV__ variabili indipendenti continue;

* __RACE__ variabile indipendente discreta a 3 livelli.

__Soluzione__

Importiamo i dati.

```{r load_lowbwth, eval = TRUE, collapse = TRUE }
lw = read.table( "LOWBWTdata.txt", head = TRUE )
attach( lw )
```

```{r mod_lowbwth, eval = TRUE, collapse = TRUE }
RACE   = factor( RACE )  # tratto la variabile RACE come categorica

mod.low = glm( LOW ~ LWT + RACE + AGE + FTV, family = binomial( link = logit ) )
summary( mod.low )
```

Se ci si attiene alla sola significatività statistica si conclude che è possibile fittare un modello 'parsimonioso', contenente la sola variabile indipendente LWT. Tuttavia, come nel caso di regressione lineare multipla, l'inclusione di una variabile nel modello può avvenire per motivi differenti. Ad esempio, in questo caso, la variabile RACE è considerata in letteratura come importante nel predire l'effetto in questione, quindi la includiamo comunque nel modello ristretto.

```{r mod2_lowbwth, eval = TRUE, collapse = TRUE }
mod.low2 = glm( LOW ~ LWT + RACE, family = binomial( link = logit ) )

summary( mod.low2 )
```

Notiamo che AIC diminuisce (più l'AIC è basso, più il modello è informativo) e anche RACE acquista significatività.

```{r cfr_mod_lowbwth, eval = TRUE, collapse = TRUE }
anova( mod.low2, mod.low, test = "Chisq" )
```

L'ANOVA indica che il decremento nella devianza risultante dalla rimozione delle variabili non è statisticamente significativo. Dunque, non c'è motivo di ritenere che il modello contenente solamente LWT e RACE sia meno informativo del modello completo.

__Odds ratio__ 

Il predittore RACE è discreto a 3 livelli. In questo caso il livello 1 ( RACE = White ) viene assunto come categoria di riferimento.

```{r or_black_white_lowbwth, eval = TRUE, collapse = TRUE }
model.matrix( mod.low2 ) [ 1:15, ]

# OR 2 vs 1 ( Black vs White )
exp( coef( mod.low2 ) [ 3 ] )
```

Le donne nere sono una categoria con rischio di parto prematuro quasi 3 volte superiore alle donne bianche.

```{r or_other_white_lowbwth, eval = TRUE, collapse = TRUE }
# OR 3 vs 1 ( Other vs White )
exp( coef( mod.low2 ) [ 4 ] )
```

Le donne di altre etnie sono una categoria con rischio di parto prematuro circa 1.5 volte superiore alle donne bianche.

Facciamo un check sul GOF del modello.

```{r gof_lowbwth, eval = TRUE, collapse = TRUE }
hoslem.test( mod.low2$y, fitted( mod.low2 ), g = 6 )
#g > 3
```

Anche in questo caso, possiamo concludere che il modello dà un buon fit dei dati.


__Tabelle di classificazione__

Un modo spesso utilizzato per presentare i risultati di un fit tramite regressione logistica sono le tabelle di classificazione. In queste tabelle i dati vengono classificati secondo due chiavi:

__1.__ il valore della variabile dipendente dicotoma y;

__2.__ il valore di una variabile dicotoma $y_{mod}$, che si deriva dalla stima della probabilità ottenuta dal modello.
I valori di questa variabile si ottengono confrontando il valore della probabilità con un cut-off. Di solito si usa il valore di 0.5, ma dipende molto da quello che stiamo indagando. Per esempio, se stiamo facendo previsioni sulla presenza o l'assenza di una malattia letale, sarebbe il caso abbassare la soglia del cut-off a molto meno del $50\%$!

```{r class_lowbwth, eval = TRUE, collapse = TRUE }
soglia = 0.5

valori.reali  = lw$LOW
valori.predetti = as.numeric( mod.low2$fitted.values > soglia )
# 1 se > soglia, 0 se < = soglia
valori.predetti

tab = table( valori.reali, valori.predetti )

tab
```

La tabella riportata è detta matrice di confusione, e riporta le osservazioni dette Veri Positivi (True Positive o TP, osservazioni 1 classificate come 1), Veri Negativi (True Negative o TN, osservazioni 0 classificate come 0), Falsi Positivi (False Positive o FP, osservazioni 0 classificati come 1), Falsi Negativi (Falsi Negativi o FN, osservazioni 1 classificati come 0). 

Ci sono numerose metriche che permettono di valutare le performance del modello, a seconda delle esigenze:

* __Accuratezza__: misura dell'errore sistematico, o del bias statistico. Rappresenta la percentuale di classificazioni corrette.

$$
{\displaystyle \mathrm {Accuracy} ={\frac {\mathrm {TP} +\mathrm {TN} }{\mathrm {P} +\mathrm {N} }}={\frac {\mathrm {TP} +\mathrm {TN} }{\mathrm {TP} +\mathrm {TN} +\mathrm {FP} +\mathrm {FN} }}}
$$

* __Sensitività__: misura della proporzione dei veri positivi che sono classificati come tali (stima di $\mathbb{P}( predetto = 1 | reale = 1)$)

$$
{\displaystyle \mathrm {Sensitività} ={\frac {\mathrm {TP} }{\mathrm {P} }}={\frac {\mathrm {TP} }{\mathrm {TP} +\mathrm {FN} }}}
$$

* __Specificità__: misura della proporzione dei veri negativi che sono classificati come tali (stima di $\mathbb{P}( predetto = 0 | reale = 0 )$)

$$
{\displaystyle \mathrm {Specificità} ={\frac {\mathrm {TN} }{\mathrm {N} }}={\frac {\mathrm {TN} }{\mathrm {TN} +\mathrm {FP} }}}
$$


Alternativamente possiamo calcolare direttamente:
__Accuracy__:
```{r class_lowbwth2, eval = TRUE, collapse = TRUE }
# % di casi classificati correttamente:
round( sum( diag( tab ) ) / sum( tab ), 2 )

# % di casi misclassificati:
round( ( tab [ 1, 2 ] + tab [ 2, 1 ] ) / sum( tab ), 2 )
```

__Sensitività__:
```{r sens_lowbwth, eval = TRUE, collapse = TRUE }
sensitivita =  tab [ 2, 2 ] /( tab [ 2, 1 ] + tab [ 2, 2 ] ) 
sensitivita
```

__Specificità__: 
```{r spec_lowbwth, eval = TRUE, collapse = TRUE }
specificita = tab[ 1, 1 ] /( tab [ 1, 2 ] + tab [ 1, 1 ] )
specificita
```



## 3. Curva ROC

Costruire la Curva ROC a partire dai valori predetti per la risposta dal modello `mod.low2` dell'analisi della variabile LOWBT.

__Soluzione__

Le curve ROC (Receiver Operating Characteristic, anche note come Relative Operating Characteristic) sono degli schemi grafici per un classificatore binario. Lungo i due assi si possono rappresentare la sensibilità e (1-specificità), rispettivamente rappresentati da True Positive Rate (TPR, frazione di veri positivi) e False Positive Rate (FPR, frazione di falsi positivi). 

Una curva ROC è il grafico dell'insieme delle coppie (FP, TP) al variare di un parametro del classificatore. Per esempio, in un classificatore a soglia, si calcola la frazione di veri positivi e quella di falsi positivi per ogni possibile valore della soglia; tutti i punti così ottenuti nello spazio FP-TP descrivono la curva ROC.

```{r ROC_lowbwth, eval = TRUE, collapse = TRUE }
fit2 = mod.low2$fitted


#media campionaria della prob di sopravvivenza nel campione

soglia_roc  = seq( 0, 1, length.out = 2e2 )
lens = length( soglia_roc )-1
ascissa_roc  = rep( NA, lens )
ordinata_roc = rep( NA, lens )

for ( k in 1 : lens )
{
  soglia = soglia_roc [ k ]

  classification = as.numeric( sapply( fit2, function( x ) ifelse( x < soglia, 0, 1 ) ) )

  #  ATTENZIONE, voglio sulle righe il vero e sulle colonne il predetto
  # t.misc = table( lw$LOW, classification )

  ordinata_roc[ k ] = sum( classification[ which( lw$LOW == 1 ) ] == 1 ) /
    length( which( lw$LOW == 1 ) )

  ascissa_roc[ k ] = sum( classification[ which( lw$LOW == 0 ) ] == 1 ) /
    length( which( lw$LOW == 0 ) )

  # ordinata_roc [ k ]  = t.misc [ 1, 1 ] /( t.misc [ 1, 1 ] + t.misc [ 1, 2 ] )
  #
  # ascissa_roc [ k ]  = t.misc [ 2, 1 ] /( t.misc [ 2, 1 ] + t.misc [ 2, 2 ] )
}
```

Visualizziamo la curva ROC.

```{r vis_ROC_lowbwth, eval = TRUE, collapse = TRUE }

plot( ascissa_roc, ordinata_roc, type = "l", xlab = "1 - Specificity", ylab = "Sensitivity",
      main = "Curva ROC", lwd = 2, col = 'darkblue', ylim = c( 0, 1 ), xlim = c( 0, 1 ) )
abline( h = c( 0, 1 ), v = c( 0, 1 ), lwd = 1, lty = 2, col = 'red' )
abline( a = 0, b = 1, lty = 2, col = 'black' )

# qual era il nostro punto?
abline( v = 1 - specificita,  h = sensitivita, lty = 3, col = 'blue' )
points( 1 - specificita, sensitivita, pch = 4, lwd = 3, cex = 1.5, col = 'blue' )
```
Le linee tratteggiate corrispondono alle due metriche calcolate con la threshold = 0.5 che abbiamo scelto. 

Attraverso l'analisi delle curve ROC si valuta la capacità del classificatore di discernere, ad esempio, tra un insieme di popolazione sana e malata, calcolando l'area sottesa alla curva ROC (Area Under Curve, AUC). Il valore di AUC, compreso tra 0 e 1, equivale infatti alla probabilità che il risultato del classificatore applicato ad un individuo estratto a caso dal gruppo dei malati sia superiore a quello ottenuto applicandolo ad un individuo estratto a caso dal gruppo dei sani.

```{r auc, eval = TRUE, collapse = TRUE }
roc_obj <- roc(valori.reali, valori.predetti)
auc(roc_obj)
```

Se AUC < 0.5, possiamo invertire i positivi e i negativi.